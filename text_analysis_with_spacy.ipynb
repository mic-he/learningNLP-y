{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with spaCy\n",
    "\n",
    "SpaCy is a modern natural language processing library for Python https://spacy.io/\n",
    "\n",
    "We follow material found on offical github https://github.com/explosion/spacy-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, install spaCy library and language-specific resources, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install spacy\n",
    "#!python3 -m spacy download it # where \"it\" is Italian language code, use \"en\" for English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import library and language resources in python (it might take a while):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Pride and Prejudice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduce the tutorial available at: https://github.com/explosion/spacy-notebooks/blob/master/notebooks/conference_notebooks/pycon_nlp/01_pride_and_predjudice.ipynb\n",
    "\n",
    "The text of the book can be downloaded here: https://github.com/explosion/spacy-notebooks/blob/master/notebooks/conference_notebooks/pycon_nlp/data/pride_and_prejudice.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we define a convenient function to load text file, then we use it to load the book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = read_file('data/pride_and_prejudice.txt')\n",
    "\n",
    "# then parse it with spacy\n",
    "processed_text = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7761\n",
      "[\", My dear Mr. Bennet,\" said his lady to him one day, \"have you heard that\n",
      "Netherfield Park is let at last?, \"\n",
      "\n",
      ", Mr. Bennet replied that he had not.\n",
      "\n",
      ", \", But it is,\" returned she; \"for Mrs. Long has just been here, and she\n",
      "told me all about it., \"\n",
      "\n",
      ", Mr. Bennet made no answer.\n",
      "\n",
      ", \"Do you not want to know who has taken it?, \" cried his wife impatiently.\n",
      "\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# how many sentences in the book?\n",
    "sentences = [s for s in processed_text.sents]\n",
    "print(len(sentences))\n",
    "\n",
    "# take a look at some sentences\n",
    "print(sentences[15:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find names of characters using named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We leverage named entities recognition to build a list of characters' names and the number of occurences in the text.\n",
    "\n",
    "First, we  import the Counter package from library collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract all the personal names and count their occurrences \n",
    "# output is a list in the following form: [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266) ...].\n",
    "\n",
    "def find_character_occurences(doc):\n",
    "    \"\"\"\n",
    "    Return a list of names from `doc` with corresponding occurences.\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: list of tuples in form\n",
    "        [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266)]\n",
    "    \"\"\"\n",
    "    \n",
    "    characters = Counter() # initialize counter\n",
    "    for ent in processed_text.ents: # cycle through named entities recognized in spacy doc\n",
    "        if ent.label_ == 'PERSON': # filter only person names\n",
    "            characters[ent.lemma_] += 1 # add 1 to the sum of occurrences of the found name\n",
    "            \n",
    "    return characters.most_common() # without integer argument, it simply return sorted list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elizabeth', 620), ('Darcy', 364), ('Bennet', 290), ('Jane', 285), ('Bingley', 252), ('Wickham', 185), ('Collins', 178), ('Gardiner', 94), ('Lizzy', 93), ('Lady Catherine', 84), ('Kitty', 69), ('Longbourn', 60), ('Lydia', 50), ('Charlotte', 45), ('Pemberley', 42), ('Forster', 39), ('Mary', 37), ('William', 34), ('Fitzwilliam', 33), ('Hurst', 33)]\n"
     ]
    }
   ],
   "source": [
    "print(find_character_occurences(processed_text)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elizabeth', 620), ('Darcy', 364), ('Bennet', 290), ('Jane', 285), ('Bingley', 252), ('Wickham', 185), ('Collins', 178), ('Gardiner', 94), ('Lizzy', 93), ('Lady Catherine', 84), ('Kitty', 69), ('Longbourn', 60), ('Lydia', 50), ('Charlotte', 45), ('Pemberley', 42), ('Forster', 39), ('Mary', 37), ('William', 34), ('Fitzwilliam', 33), ('Hurst', 33), ('Project Gutenberg - tm', 31), ('Meryton', 27), ('Phillips', 26), ('Catherine', 21), ('Lady Lucas', 18), ('Maria', 18), ('Derbyshire', 17), ('Netherfield', 17), ('de Bourgh', 16), ('Kent', 14), ('Long', 14), ('Miss Lucas', 13), ('Denny', 12), ('Lucases', 10), ('Caroline', 9), ('Jenkinson', 9), ('Reynolds', 9), ('William Lucas', 9), ('Lucas', 8), ('Hill', 8), ('Elizabeth Bennet', 8), ('longbourn', 8), ('Gutenberg - tm', 8), ('Eliza', 7), ('Charlotte Lucas', 7), ('Charles', 7), ('George Wickham', 7), ('Lady Catherine de Bourgh', 6), ('Gutenberg', 6), ('Aye', 6)]\n"
     ]
    }
   ],
   "source": [
    "print(find_character_occurences(processed_text)[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find words that describe a character & find characters that are doing specific actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leveraging subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_character_adjectives(doc, character_lemma):\n",
    "    \"\"\"\n",
    "    Find all the adjectives related to `character_lemma` in `doc`\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :param character_lemma: string object\n",
    "    :return: list of adjectives related to `character_lemma`\n",
    "    \"\"\"\n",
    "    \n",
    "    adjectives = []\n",
    "    for ent in processed_text.ents:\n",
    "        if ent.lemma_ == character_lemma:\n",
    "            for token in ent.subtree:\n",
    "                if token.pos_ == 'ADJ': # Replace with if token.dep_ == 'amod':\n",
    "                    adjectives.append(token.lemma_)\n",
    "    \n",
    "    for ent in processed_text.ents:\n",
    "        if ent.lemma_ == character_lemma:\n",
    "            if ent.root.dep_ == 'nsubj':\n",
    "                for child in ent.root.head.children:\n",
    "                    if child.dep_ == 'acomp':\n",
    "                        adjectives.append(child.lemma_)\n",
    "    \n",
    "    return adjectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['surprised', 'unwilling', 'least', 'grave', 'late', 'late', 'late', 'late', 'intimate', 'confidential', 'present', 'late', 'superior', 'evident', 'late', 'late', 'poor', 'last', 'little', 'disagreeable', 'clever', 'worth', 'delighted', 'studious', 'sorry', 'unworthy', 'answerable', 'impatient', 'ashamed', 'kind', 'handsome', 'proud', 'tall', 'punctual', 'engage', 'delight', 'fond']\n"
     ]
    }
   ],
   "source": [
    "print(get_character_adjectives(processed_text, 'Darcy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find characters that are 'talking', 'saying', 'doing' something the most.\n",
    "\n",
    "character_verb_counter = Counter()\n",
    "VERB_LEMMA = 'say'\n",
    "\n",
    "for ent in processed_text.ents:\n",
    "    if ent.label_ == 'PERSON' and ent.root.head.lemma_ == VERB_LEMMA:\n",
    "        character_verb_counter[ent.text] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elizabeth', 46), ('Bennet', 30), ('Bingley', 16), ('Jane', 13), ('Darcy', 13), ('Fitzwilliam', 5), ('Lady Catherine', 5), ('Lizzy', 5), ('Gardiner', 5), ('Charlotte', 5)]\n"
     ]
    }
   ],
   "source": [
    "print(character_verb_counter.most_common(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
