{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to generate names with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is available at https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html and it can be seen as a follow up to https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html.\n",
    "\n",
    "We use a character-level recurrent nn to generate names given a language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data\n",
    "The data is available at https://download.pytorch.org/tutorial/data.zip. The folder `data/names` contains 18 Unicode text files, one for each of 18 languages, with names such as `[Language].txt`.\n",
    "\n",
    "With the following code we read the files, convert the data to ASCII and create a dictionary with shape `{language: [name1, name2, ...]}`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O'Neal\n"
     ]
    }
   ],
   "source": [
    "# turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "all_letters = string.ascii_letters + \" .,;'-\" # our alphabet\n",
    "n_letters = len(all_letters) + 1 # plus 1 because of EOS marker\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "# for example:\n",
    "print(unicodeToAscii(\"O'Néàl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# categories: 18 ['Greek', 'German', 'Portuguese', 'Irish', 'Scottish', 'Czech', 'English', 'Vietnamese', 'Polish', 'Korean', 'French', 'Spanish', 'Arabic', 'Chinese', 'Dutch', 'Japanese', 'Italian', 'Russian']\n"
     ]
    }
   ],
   "source": [
    "# read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "# get a list of paths for each of the files found with a certain pattern (see below)\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# build the category_lines dictionary, a list of lines (i.e. names) per category (i.e. languages)\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "for filename in findFiles('data/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('# categories:', n_categories, all_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a character-level recurrent nn. The input is a pair `<language, name>` where `name` is encoded as a matrix where each row is the tensor corresponding to a letter in the name. The output is a probability distribution over letters (roughly, the probability of the next letter given the previous).\n",
    "\n",
    "(A picture of the model is available at https://i.imgur.com/jzVrf7f.png.)\n",
    "\n",
    "The source of recurrence is the fact that a hidden layer computed from the input at a gvien stage (i.e. a letter in the name) is fed to the nn together with the input pair itself at the following stage (i.e. the following letter); moreover, the output at each stage is also fed to the nn as input in the following stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(n_categories + input_size + hidden_size, hidden_size) # linear transf. input-to-hidden\n",
    "        self.i2o = nn.Linear(n_categories + input_size + hidden_size, output_size) # input-to-(intermediate-)output\n",
    "        self.o2o = nn.Linear(hidden_size + output_size, output_size) #(intermediate-)output-to-(actual-)output\n",
    "        self.dropout = nn.Dropout(0.1) # the intermediate output is filtered with dropout\n",
    "        self.softmax = nn.LogSoftmax(dim=1) # then transformed into prob. distribution, the actual output\n",
    "\n",
    "    def forward(self, category, input, hidden):\n",
    "        input_combined = torch.cat((category, input, hidden), 1) # input pair and hidden layer are combined here\n",
    "        hidden = self.i2h(input_combined)\n",
    "        output = self.i2o(input_combined)\n",
    "        output_combined = torch.cat((hidden, output), 1)\n",
    "        output = self.o2o(output_combined)\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
